---
title: "FE8828 Programming Web Applications in Finance"
subtitle: "<sub> Week 5 <br> Applications </sub>"
author: "Dr. Yang Ye <sub> <Email:yy@runchee.com> </sub>"
date: "Nov 30, 2017"
# runtime: shiny
---

```{r setup, include=FALSE}
library(fOptions)
library(tidyverse)
library(lubridate)
library(bizdays)
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(maps)
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = FALSE, fig.align="center", collapse = TRUE, cache = TRUE)
chunk <- "```"
inline <- function(x = "") paste0("`` `r ", x, "` ``")
bank <- read.csv("https://goo.gl/PBQnBt", sep = ";")
token_qd <- 'JyeshGuNBGDbbaYoNURG'
token_av <- 'QWM66H05ENYFRDPO'
```
<style type="text/css">
code.r{ /* Code block */
    font-size: 20px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 17px;
}
</style>

# Lecture 10: Model
Data modeling is find quantitative relationship between variables relating to an outcome.

# Our data

```{r, echo = T}
models <- mtcars %>% 
  split(.$cyl) %>% 
  map(function(df) lm(mpg ~ wt, data = df))

models <- mtcars %>% 
  split(.$cyl) %>% 
  map(~lm(mpg ~ wt, data = .))
```
# Model with Modelr

First, you define a family of models that express a precise, but generic, pattern that you want to capture.
For example, the pattern might be a straight line, or a quadatric curve. You will express the model family as
an equation like y = a_1 * x + a_2 or y = a_1 * x ^ a_2. Here, x and y are known variables from your data,
and a_1 and a_2 are parameters that can vary to capture different patterns.

Next, you generate a fitted model by finding the model from the family that is the closest to your data.
This takes the generic model family and makes it specific, like y = 3 * x + 7 or y = 9 * x ^ 2.

```{r, echo = T}
install.package("purrr", "modelr")
library(purrr)
library(modelr)
```

# Data set
sim1

```{r, echo = T}
model1 <- function(a, data) {
  a[1] + data$x * a[2]
}

measure_distance <- function(mod, data) {
  diff <- data$y - model1(mod, data)
  sqrt(mean(diff ^ 2))
}
best <- optim(c(0, 0), measure_distance, data = sim1)
best$par

sim1_mod <- lm(y ~ x, data = sim1)
coef(sim1_mod)
```

# Regression Model
```{r, echo = T}
library(ggplot2)

set.seed(123)
N <- 1000
x <- rnorm(N)
f <- function(x) 50*x^2/(1 + 4*x) # data-simulating function

y <- f(x) + rnorm(N, sd=3)

point_data <- data.frame(x, y)

library(tidyverse)

ggplot(point_data, aes(x=x, y=y)) + 
  geom_point() + 
  ylim(-100, 100) + 
  ggtitle("simulated data points")

fit_pade <- function(point_data){
  fit <- lm(y ~ x + I(x^2) + I(y*x) + I(y*x^2), point_data)
  lm_coef <- as.list(coef(fit))
  names(lm_coef) <- c("a0", paste0(rep(c('a','b'), each=2), 1:2))
  
  with(lm_coef, function(x)(a0 + a1*x + a2*x^2)/(1 - b1*x - b2*x^2))
}

plot_fitted_function <- function(x_data, fitted_fun, title){
  x_data$y_hat <- fitted_fun(x_data$x)
  g <- ggplot(x_data, aes(x=x, y=y)) + 
    geom_point() + ylim(-100, 100) +
    geom_line(aes(y=y_hat), col="red", size=1) + 
    ggtitle(title)
  
  plot(g)
}

pade_approx <- fit_pade(point_data)

plot_fitted_function(point_data, pade_approx, title="fitted function")

function_list <- list(
  function(x) (100 - 50*x - 100*x^2)/(1 - 50*x - 5*x^2),
  function(x) (100 - 50*x - 100*x^2)/(1 - 10*x - 5*x^2),
  function(x) (100 - 50*x - 100*x^2)/(1 - 10*x - 10*x^2)
)

for (f in function_list){
  sim_data <- point_data %>% mutate(y=f(x) + 
                                      rnorm(nrow(point_data), sd=3))
  plot_fitted_function(sim_data, fit_pade(sim_data), 
                       title=as.character(deparse(f))[2])
}
```

# K-means
# K-means between two categorical variables
dev.off()
data.model <- select(bank, balance, education) %>% mutate(education = factor(education))
plot(data.model)
combination <- model.matrix(~ . - 1, data.model)
data.model$cl <- kmeans(combination, 4)$cluster
with(data.model, plot(balance, education, col = cl))

# K-means between one categorical variable + one numeric variable
dev.off()
data.model <- select(bank, job, education) %>% mutate(job = factor(job), education = factor(education))
plot(data.model)
combination <- model.matrix(~ . - 1, data.model)
data.model$cl <- kmeans(combination, 2)$cluster
with(data.model, plot(job, education, col = cl))

# K-means between two numeric variables
dev.off()
data.model <- select(bank, balance, duration)
plot(data.model)
data.model$cl <- kmeans(data.model[, 1:2], 4)$cluster
with(data.model, plot(balance, duration, col = cl))
with(data.model, text(balance, duration, col=cl))


# Apply our data to model.
```{r, echo = T}
library(modelr)

mod <- lm(log(balance) ~ log(age), data = bank)

bank1 <- filter(bank, default == "no" & balance > 0)
mod <- lm(log(balance) ~ log(age), data = bank1)

bank2 <- bank1 %>% 
  add_residuals(mod) %>% 
  mutate(resid = exp(resid))

ggplot(data = bank2) + 
  geom_point(mapping = aes(x = age, y = resid))
```

# prediction is for the new data
sim1 %>%
data_grid(x) %>% # generate data set.
add_predictions(sim1_mod) 

ggplot(sim1, aes(x)) +
  geom_point(aes(y = y)) +
  geom_line(aes(y = pred), data = grid, colour = "red", size = 1)

# residual is for the existing data
add_residuals(sim1_mod, sim1)

ggplot(sim1, aes(resid)) + 
  geom_freqpoly(binwidth = 0.5)

# apply it for the bank dataset
ggplot(bank) + geom_bar(aes(x = age, fill = y))

model_matrix(bank, y ~ age)

bank_mod <- lm(y ~ age, data = mutate(bank, y = ifelse(y == "yes", 1, 0)))

# add_prediction
mutate(bank, y = ifelse(y == "yes", 1, 0)) %>% data_grid(age) %>% add_predictions(bank_mod)
mutate(bank, y = ifelse(y == "yes", 1, 0)) %>% data_grid(age) %>% add_predictions(bank_mod) %>% ggplot(aes(x = age, y = pred)) + geom_point()

mutate(bank, y = ifelse(y == "yes", 1, 0)) %>% add_residuals(bank_mod) %>%
ggplot(aes(resid)) + 
  geom_freqpoly(binwidth = 0.05) 

# 2nd model
bank_mod <- lm(y ~ age * job, data = mutate(bank, y = ifelse(y == "yes", 1, 0)))
mutate(bank, y = ifelse(y == "yes", 1, 0)) %>% data_grid(age, job) %>%
  add_predictions(bank_mod) %>%
  ggplot(aes(x = age, colour = job)) + geom_line(aes(y = pred))

mutate(bank, y = ifelse(y == "yes", 1, 0)) %>% add_residuals(bank_mod) %>%
ggplot(aes(x = age, resid, colour = job)) +
  geom_point()

# model 
model_matrix(df, y ~ I(x^2) + x)

# try age with balance?

with different jobs

by_job <- group_by(bank, job) %>% nest()
job_balance <- function(df) {
  lm(balance ~ age, data = df)
}
models <- mutate(by_job, model = purrr::map(data, job_balance))

by_job_res <- models %>%
  mutate(resids = map2(data, model, add_residuals))

resids <- unnest(by_job_res, resids)

resids %>% 
  ggplot(aes(age, resid)) +
    geom_line(aes(colour = job)) + 
    geom_smooth(se = FALSE)

resids %>%
  ggplot(aes(age, resid, group = job)) +
    geom_line(alpha = 1 / 3) + 
    facet_wrap(~job)

# natural spine

mod1 <- lm(y ~ ns(x, 1), data = sim5)

mod1 <- lm(y ~ x1 + x2, data = sim3)
mod2 <- lm(y ~ x1 * x2, data = sim3)

# Lecture 11: Financial Application

# Starter

```{r echo = FALSE, comment = ""}
cat(htmltools::includeText("example/biorhythm.R"))
```

```{r, echo = F}
source("example/biorhythm.R")
```

# Main course

- We need following packages as a start. Use c() to install multiple packages.
      
    install.packages(c("tidyquant", "Quandl", "fOptions", "fExoticOptions", "dygraph", "forecast"))

- tidyquant is also a collection of packages: xts/quantmod

- Please validate option pricing code. I found Asian Option in `fExoticOptions` is strangely implemented.

# tidyquant or Quandl
Determining factor:

- tidyquant/quantmod can connect to various services: google, yahoo (retiring), av (AlphaAdvantage).
- Quandl only connects to Quandl
- It's subject where you can find the data.
    - US ETF on Quandl is premium. ETF in Google/AlphaAdvantage is free.

Technical details:

- quantmod returns `xts` object. Quandl returns data frame or `xts`
- quantmod use assign to create variable. Quandl returns an object
- xts can `collapse` to daily, weekly, monthly.

# Tidyquant/quantmod

```{r, echo = T}
library(tidyquant)

# use Google
getSymbols('SPY', src = 'google', adjusted = TRUE, output.size = 'full')
str(SPY)

# Sign up with AlphaAdvantage to get a token
getSymbols('SPY', src = 'av', adjusted = TRUE, output.size = 'full', api.key = token_av)
str(SPY)

head(SPY)
tail(SPY)

symbols <- c("MSFT", "AAPL")
getSymbols(symbols, src = 'google', adjusted = TRUE, from = "2016-01-01")

```

# `xts` object
- xts is a wide format. In contrast, ggplot/tidy uses long format.
- We have gather/spread to convert between long/wide format.
- Create xts object: put index, date usually, aside, and store prices in columns.

        library(xts)    
        # if df is a data frame.
        # Date | V | GS
        xts1 <- xts(x=df[, -1, drop = F], order.by = df[1])

        # coredata: returns a matrix from xts objects
        # index: vector of any Date, POSIXct, chron, yearmon, yearqtr, or DateTime classes
        core_data <- coredata(xts2)
        index(xts1)

# Get data from `xts` object

```{r, echo = T}
str(SPY)
```

```{r, echo = T, results = "hide"}
SPY2003 <- SPY["2003"]
SPY2 <- SPY["2003/2007"]
SPY3 <- SPY["2003-03-01/2007-07-01"]
SPY4 <- SPY["/2007-07-01"]
SPY5 <- SPY["2007-07-01/"]
SPY6 <- SPY["2007-07-01/", "SPY.High"]
SPY6 <- SPY["2007-07-01/", "SPY.High/SPY.Close"]
```

# Quandl
```{r, echo = T}
library(Quandl)
library(tidyverse)

# Sign up with Quandl to get a token
# token <- "xxxx"
Quandl.api_key(token_qd)
# You don't get SPY: SPDR 500 ETF
rates <- Quandl(c("EOD/SPY"), start_date="2000-01-01", end_date="2013-06-07")
# You get price for Visa
rates <- Quandl(c("EOD/V"), start_date="2000-01-01", end_date="2013-06-07" )
# Get price for Visa in xts
rates <- Quandl(c("EOD/V"), start_date="2000-01-01", end_date="2013-06-07", type = "xts")
```

# Quandl
```{r, echo = T}
library(Quandl)					# Quandl package
library(ggplot2)				# Package for plotting
library(tidyverse)				# Package for reshaping data

Quandl.api_key(token_qd)				# Authenticate your token
# Build vector of currencies
rates <- Quandl(c("FRED/DEXUSAL", "FRED/DEXBZUS", "FRED/DEXUSUK", "FRED/DEXCHUS"),start_date="2000-01-01",end_date = "2017-11-30")
colnames(rates) <- c("Date", "AUD/USD", "USD/BRL", "GBP/USD", "USD/CNY")
meltdf <- gather(rates, key = "CCY", value = "Rate", -Date)

ggplot(meltdf, aes(x = Date, y = value, colour = CCY, group = CCY)) +
  geom_line() +
  scale_colour_manual(values=1:22)+
  ggtitle("Major Currency Exchange Rates in USD") +
  theme_minimal()
```

# Quandl and forecast

```{r, echo = T}
cat(htmltools::includeText("example/52-quandl-forecast.R"))
```

```{r, echo = F}
source("example/52-quandl-forecast.R")
```

# dygraph

dygraph for xts
https://rstudio.github.io/dygraphs/shiny.html

    dygraphOutput("dygraph")

    dygraph(oil_combined_xts, main = "Oil Prices: Historical and Forecast") %>%
      # Add the actual series
      dySeries("Actual", label = "Actual") %>%
      # Add the three forecasted series
      dySeries(c("Lo_95", "Forecast", "Hi_95"))

# Quandl/Shiny/dygraph

```{r, echo = T}
cat(htmltools::includeText("example/shiny-51-quandl.R"))
```

# Portfolio analysis

```{r, echo = T}
cat(htmltools::includeText("example/53-portfolio-2.R"))
```

# Assingment
Part II

1. Bank management 
- We also need to generate following monthly reports:
    - Risk department: Total balance, Total receivable from credit, Top 10 High and low-risk client (i.e. balance - spent credit).
    - Customer department: Top 10 balance customer, Top 10 spending customer, Top 10 saving customer.
    - Treasury department: Interest rate payable monthly, assume annual interest is 0.25%.

2. Delta Hedging
Show case how delta hedging works as a trading strategy.

- Show how one trade works
- Backtest for available history.

Assumption:

- You hold 100 ATM call/put option which expires in 30 days (calendar days). You just need to do either Call or Put.
- You start to do delta hedging daily immediately till 2nd last day. You close stock position in the last day.
- Delta hedging: calculate the delta from option, negate it, that's the quantity what you need to hold over 1 day. Repeat for every trading day.
- Daily PnL: (option premium change) + (stock holding quantity * price change).

- You can get your favorite stocks here. There is one year of data.
  https://marketchameleon.com/Overview/{Stock Code}/DailyHistory/
  https://marketchameleon.com/Overview/GS/DailyHistory/
- Daily IV30 is provided.
- As underlying is equity, dividend yield is applicable for B-S valuation
- US risk-free rate for 1M: 0.8% (annualized)

For one trade

- Daily PnL v.s. Time to expiry: split into option and stock.  
- Final PnL: accumulative of Daily PnL. split into option and stock
- Max Drawdown: accumulative of Daily PnL, max - min.
- Sharpe ratio: Sharpe ratio = (Mean of Daily PnL − Risk-free rate)/Standard deviation of Daily PnL

For backtest:

- Distribution of Final PnL
- Distribution of Max Drawdown
- Final PnL v.s. Option Expiry Date
- ...

- in R Markdown
