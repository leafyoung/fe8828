---
title: "FE8828 Programming Web Applications in Finance"
subtitle: "<sub> Week 5 <br> Applications </sub>"
author: "Dr. Yang Ye <sub> <Email:yy@runchee.com> </sub>"
date: "Nov 30, 2017"
# runtime: shiny
---

```{r setup, include=FALSE}
library(fOptions)
library(tidyverse)
library(lubridate)
library(bizdays)
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(maps)
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = FALSE, fig.align="center", collapse = TRUE, cache = TRUE)
chunk <- "```"
inline <- function(x = "") paste0("`` `r ", x, "` ``")
bank <- read.csv("https://goo.gl/PBQnBt", sep = ";")
```
<style type="text/css">
code.r{ /* Code block */
    font-size: 20px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 17px;
}
</style>

# Lecture 10: Model
Data modeling is find quantitative relationship between variables relating to an outcome.

# Our data

```{r, echo = T}
models <- mtcars %>% 
  split(.$cyl) %>% 
  map(function(df) lm(mpg ~ wt, data = df))

models <- mtcars %>% 
  split(.$cyl) %>% 
  map(~lm(mpg ~ wt, data = .))
```
# Model with Modelr

First, you define a family of models that express a precise, but generic, pattern that you want to capture.
For example, the pattern might be a straight line, or a quadatric curve. You will express the model family as
an equation like y = a_1 * x + a_2 or y = a_1 * x ^ a_2. Here, x and y are known variables from your data,
and a_1 and a_2 are parameters that can vary to capture different patterns.

Next, you generate a fitted model by finding the model from the family that is the closest to your data.
This takes the generic model family and makes it specific, like y = 3 * x + 7 or y = 9 * x ^ 2.

```{r, echo = T}
install.package("purrr", "modelr")
library(purrr)
library(modelr)
```

# Data set
sim1

```{r, echo = T}
model1 <- function(a, data) {
  a[1] + data$x * a[2]
}

measure_distance <- function(mod, data) {
  diff <- data$y - model1(mod, data)
  sqrt(mean(diff ^ 2))
}
best <- optim(c(0, 0), measure_distance, data = sim1)
best$par

sim1_mod <- lm(y ~ x, data = sim1)
coef(sim1_mod)
```

# Regression Model
```{r, echo = T}
library(ggplot2)

set.seed(123)
N <- 1000
x <- rnorm(N)
f <- function(x) 50*x^2/(1 + 4*x) # data-simulating function

y <- f(x) + rnorm(N, sd=3)

point_data <- data.frame(x, y)

library(tidyverse)

ggplot(point_data, aes(x=x, y=y)) + 
  geom_point() + 
  ylim(-100, 100) + 
  ggtitle("simulated data points")

fit_pade <- function(point_data){
  fit <- lm(y ~ x + I(x^2) + I(y*x) + I(y*x^2), point_data)
  lm_coef <- as.list(coef(fit))
  names(lm_coef) <- c("a0", paste0(rep(c('a','b'), each=2), 1:2))
  
  with(lm_coef, function(x)(a0 + a1*x + a2*x^2)/(1 - b1*x - b2*x^2))
}

plot_fitted_function <- function(x_data, fitted_fun, title){
  x_data$y_hat <- fitted_fun(x_data$x)
  g <- ggplot(x_data, aes(x=x, y=y)) + 
    geom_point() + ylim(-100, 100) +
    geom_line(aes(y=y_hat), col="red", size=1) + 
    ggtitle(title)
  
  plot(g)
}

pade_approx <- fit_pade(point_data)

plot_fitted_function(point_data, pade_approx, title="fitted function")

function_list <- list(
  function(x) (100 - 50*x - 100*x^2)/(1 - 50*x - 5*x^2),
  function(x) (100 - 50*x - 100*x^2)/(1 - 10*x - 5*x^2),
  function(x) (100 - 50*x - 100*x^2)/(1 - 10*x - 10*x^2)
)

for (f in function_list){
  sim_data <- point_data %>% mutate(y=f(x) + 
                                      rnorm(nrow(point_data), sd=3))
  plot_fitted_function(sim_data, fit_pade(sim_data), 
                       title=as.character(deparse(f))[2])
}
```

# K-means
# K-means between two categorical variables
dev.off()
data.model <- select(bank, balance, education) %>% mutate(education = factor(education))
plot(data.model)
combination <- model.matrix(~ . - 1, data.model)
data.model$cl <- kmeans(combination, 4)$cluster
with(data.model, plot(balance, education, col = cl))

# K-means between one categorical variable + one numeric variable
dev.off()
data.model <- select(bank, job, education) %>% mutate(job = factor(job), education = factor(education))
plot(data.model)
combination <- model.matrix(~ . - 1, data.model)
data.model$cl <- kmeans(combination, 2)$cluster
with(data.model, plot(job, education, col = cl))

# K-means between two numeric variables
dev.off()
data.model <- select(bank, balance, duration)
plot(data.model)
data.model$cl <- kmeans(data.model[, 1:2], 4)$cluster
with(data.model, plot(balance, duration, col = cl))
with(data.model, text(balance, duration, col=cl))


# Apply our data to model.

```{r, echo = T}
library(modelr)

mod <- lm(log(balance) ~ log(age), data = bank)

bank1 <- filter(bank, default == "no" & balance > 0)
mod <- lm(log(balance) ~ log(age), data = bank1)

bank2 <- bank1 %>% 
  add_residuals(mod) %>% 
  mutate(resid = exp(resid))

ggplot(data = bank2) + 
  geom_point(mapping = aes(x = age, y = resid))
```

# prediction is for the new data
sim1 %>%
data_grid(x) %>% # generate data set.
add_predictions(sim1_mod) 

ggplot(sim1, aes(x)) +
  geom_point(aes(y = y)) +
  geom_line(aes(y = pred), data = grid, colour = "red", size = 1)

# residual is for the existing data
add_residuals(sim1_mod, sim1)

ggplot(sim1, aes(resid)) + 
  geom_freqpoly(binwidth = 0.5)

# apply it for the bank dataset
ggplot(bank) + geom_bar(aes(x = age, fill = y))

model_matrix(bank, y ~ age)

bank_mod <- lm(y ~ age, data = mutate(bank, y = ifelse(y == "yes", 1, 0)))

# add_prediction
mutate(bank, y = ifelse(y == "yes", 1, 0)) %>% data_grid(age) %>% add_predictions(bank_mod)
mutate(bank, y = ifelse(y == "yes", 1, 0)) %>% data_grid(age) %>% add_predictions(bank_mod) %>% ggplot(aes(x = age, y = pred)) + geom_point()

mutate(bank, y = ifelse(y == "yes", 1, 0)) %>% add_residuals(bank_mod) %>%
ggplot(aes(resid)) + 
  geom_freqpoly(binwidth = 0.05) 

# 2nd model
bank_mod <- lm(y ~ age * job, data = mutate(bank, y = ifelse(y == "yes", 1, 0)))
mutate(bank, y = ifelse(y == "yes", 1, 0)) %>% data_grid(age, job) %>%
  add_predictions(bank_mod) %>%
  ggplot(aes(x = age, colour = job)) + geom_line(aes(y = pred))

mutate(bank, y = ifelse(y == "yes", 1, 0)) %>% add_residuals(bank_mod) %>%
ggplot(aes(x = age, resid, colour = job)) +
  geom_point()

# model 
model_matrix(df, y ~ I(x^2) + x)

# try age with balance?

with different jobs

by_job <- group_by(bank, job) %>% nest()
job_balance <- function(df) {
  lm(balance ~ age, data = df)
}
models <- mutate(by_job, model = purrr::map(data, job_balance))

by_job_res <- models %>%
  mutate(resids = map2(data, model, add_residuals))

resids <- unnest(by_job_res, resids)

resids %>% 
  ggplot(aes(age, resid)) +
    geom_line(aes(colour = job)) + 
    geom_smooth(se = FALSE)

resids %>%
  ggplot(aes(age, resid, group = job)) +
    geom_line(alpha = 1 / 3) + 
    facet_wrap(~job)

# natural spine

mod1 <- lm(y ~ ns(x, 1), data = sim5)

mod1 <- lm(y ~ x1 + x2, data = sim3)
mod2 <- lm(y ~ x1 * x2, data = sim3)

# Lecture 11: Financial Application

# Option pricing

library(fOption)
library(fExoticOptions)

Word of caution:
- Please validate option pricing code. I found Asian Option in fExoticOptions is strange.

# xts

library(xts)
xts object => store prices and retrieve.

Convert from data to Xts object

get data from xts object

Create EWMA volatility

```{r, echo = T}

EWMAvol <- function(returns, lambda, rollwindow){
  EWMA.mat = matrix(NA, nrow = nrow(returns), ncol = ncol(returns))
  for (k in 1 : ncol(returns)){  
    for (j in rollwindow : nrow(returns)){
      td = returns
      data = as.matrix(td[(j - rollwindow + 1) : j, k])
      ewmaVar.mat = matrix()
      ewmaVar.mat[1] = 0
      for (i in 2 : rollwindow){
        ewmaVar.mat[i] = lambda * ewmaVar.mat[i-1]+ (1 - lambda) * data[i]^2
      }
      EWMA.mat[j, k] = sqrt(ewmaVar.mat[length(ewmaVar.mat)])
    }
  }
  return(EWMA.mat)
}
```

# Quandl

```{r, echo = T}
# with AlphaAdvantage
# QWM66H05ENYFRDPO
getSymbols('SPY', src = 'av', adjusted = TRUE, output.size = 'full', api.key = "QWM66H05ENYFRDPO")

head(SPY)
tail(SPY)
```

```{r, echo = T}
library(Quandl)					# Quandl package
library(ggplot2)				# Package for plotting
library(tidyverse)				# Package for reshaping data

Quandl.api_key(token)				# Authenticate your token
token <- 'JyeshGuNBGDbbaYoNURG'  		# Sign up with Quandl to get a token

# Build vector of currencies
rates <- Quandl(c("FRED/DEXUSAL", "FRED/DEXBZUS", "FRED/DEXUSUK", "FRED/DEXCHUS"),start_date="2000-01-01",end_date="2013-06-07" )	
meltdf <- gather(rates, key = "CCY", value = "value", -1)

ggplot(meltdf, aes(x = Date, y = value, colour = CCY, group = CCY)) +
  geom_line() +
  scale_colour_manual(values=1:22)+
  ggtitle("Major Currency Exchange Rates in USD") +
  theme_minimal()
```

Optimize for Max profit
- Bollinger band
- Gold and Oil

# 
dataChoices <- c("WTI oil" = "FRED/DCOILWTICO", #oil data from Fred
                  "Copper" = "ODA/PCOPP_USD", # copper data from ODA
                  "Gold" = "CHRIS/CME_GC1") # gold data from CME


# Object way and Data frame way

```{r echo = FALSE, comment = ""}
cat(htmltools::includeText("example/biorhythm.R"))
```

# Quandl and forecast

dygraph for xts
https://rstudio.github.io/dygraphs/shiny.html
dygraphOutput("dygraph")

dygraph(oil_combined_xts, main = "Oil Prices: Historical and Forecast") %>%
  # Add the actual series
  dySeries("Actual", label = "Actual") %>%
  # Add the three forecasted series
  dySeries(c("Lo_95", "Forecast", "Hi_95"))



```{r, echo = T}
library(Quandl)
library(dplyr)
library(xts)
library(lubridate)
library(forecast)
library(dygraphs)

# Start with daily data. Note that "type = raw" will download a data frame.
oil_daily <- Quandl("FRED/DCOILWTICO", type = "raw", collapse = "daily",  
                    start_date="2006-01-01", end_date="2017-02-28")
# Now weekely and let's use xts as the type.
oil_weekly <- Quandl("FRED/DCOILWTICO", type = "xts", collapse = "weekly",  
                     start_date="2006-01-01", end_date="2017-02-28")
# And monthly using xts as the type.
oil_monthly <- Quandl("FRED/DCOILWTICO", type = "xts", collapse = "monthly",  
                      start_date="2006-01-01", end_date="2017-02-28")

# Have a quick look at our three  objects. 
str(oil_daily)

## 'data.frame':    2809 obs. of  2 variables:
##  $ DATE : Date, format: "2017-02-28" "2017-02-27" ...
##  $ VALUE: num  54 54 54 54.5 53.6 ...
##  - attr(*, "freq")= chr "daily"

str(oil_weekly)

## An 'xts' object on 2006-01-08/2017-03-05 containing:
##   Data: num [1:583, 1] 64.2 63.9 68.2 67.8 65.4 ...
##   Indexed by objects of class: [Date] TZ: UTC
##   xts Attributes:  
##  NULL

str(oil_monthly)

## An 'xts' object on Jan 2006/Feb 2017 containing:
##   Data: num [1:134, 1] 67.9 61.4 66.2 71.8 71.4 ...
##   Indexed by objects of class: [yearmon] TZ: 
##   xts Attributes:  
##  NULL

index(oil_monthly) <- seq(mdy('01/01/2006'), mdy('02/01/2017'), by = 'months')
head(index(oil_monthly))

dygraph(oil_monthly, main = "Monthly oil Prices")

oil_6month <- forecast(oil_monthly, h = 6)

oil_6month

plot(oil_6month, main = "Oil Forecast")

oil_forecast_data <- data.frame(date = seq(mdy('03/01/2017'), 
                                           by = 'months', length.out = 6),
                                Forecast = oil_6month$mean,
                                Hi_95 = oil_6month$upper[,2],
                                Lo_95 = oil_6month$lower[,2])

head(oil_forecast_data)

oil_forecast_xts <- xts(oil_forecast_data[,-1], order.by = oil_forecast_data[,1])

# Combine the xts objects with cbind.
oil_combined_xts <- cbind(oil_monthly, oil_forecast_xts)

# Add a nicer name for the first column.
colnames(oil_combined_xts)[1] <- "Actual"

# Have a look at both the head and the tail of our new xts object. Make sure the
# NAs are correct.
head(oil_combined_xts)

##            Actual Forecast Hi_95 Lo_95
## 2006-01-01  67.86       NA    NA    NA
## 2006-02-01  61.37       NA    NA    NA
## 2006-03-01  66.25       NA    NA    NA
## 2006-04-01  71.80       NA    NA    NA
## 2006-05-01  71.42       NA    NA    NA
## 2006-06-01  73.94       NA    NA    NA

tail(oil_combined_xts)

##            Actual Forecast    Hi_95    Lo_95
## 2017-03-01     NA 53.99987 63.88081 44.11894
## 2017-04-01     NA 53.99987 68.00333 39.99642
## 2017-05-01     NA 53.99987 71.18763 36.81212
## 2017-06-01     NA 53.99987 73.88973 34.11002
## 2017-07-01     NA 53.99987 76.28590 31.71385
## 2017-08-01     NA 53.99987 78.46635 29.53340

dygraph(oil_combined_xts, main = "Oil Prices: Historical and Forecast") %>%
  # Add the actual series
  dySeries("Actual", label = "Actual") %>%
  # Add the three forecasted series
  dySeries(c("Lo_95", "Forecast", "Hi_95"))

```

# tidyquant

```{r, echo = T}
library("quantmod")
symbol <- c("MSFT", "AAPL")
getSymbols.google(symbol, env = .GlobalEnv, from = "2016-01-01")
```

# portfolio 1

```{r, echo = T}
library(tidyverse)
library(tidyquant)
library(timetk)

# The symbols vector holds our tickers. 
symbols <- c("SPY","EFA", "IJS", "EEM","AGG")

# The prices object will hold our raw price data throughout this book.
prices <- 
  getSymbols(symbols, src = 'yahoo', from = "2005-01-01", 
             auto.assign = TRUE, warnings = FALSE) %>% 
  map(~Ad(get(.))) %>% 
  reduce(merge) %>%
  `colnames<-`(symbols)

prices_monthly <- to.monthly(prices, indexAt = "last", OHLC = FALSE)
asset_returns_xts <- na.omit(Return.calculate(prices_monthly, method = "log"))

# Tidyverse method, to long, tidy format
asset_returns_long <- prices %>% 
  to.monthly(indexAt = "last", OHLC = FALSE) %>% 
  tk_tbl(preserve_index = TRUE, rename_index = "date") %>%
  gather(asset, returns, -date) %>% 
  group_by(asset) %>%  
  mutate(returns = (log(returns) - log(lag(returns))))

head(asset_returns_xts)
head(asset_returns_long)

w <- c(0.25, 0.25, 0.20, 0.20, 0.10)

asset_weights_sanity_check <- tibble(w, symbols)
asset_weights_sanity_check

sum(asset_weights_sanity_check$w)

w_1 <- w[1]
w_2 <- w[2]
w_3 <- w[3]
w_4 <- w[4]
w_5 <- w[5]

asset1 <- asset_returns_xts[,1]
asset2 <- asset_returns_xts[,2]
asset3 <- asset_returns_xts[,3]
asset4 <- asset_returns_xts[,4]
asset5 <- asset_returns_xts[,5]

portfolio_returns_byhand <-   
  (w_1 * asset1) + 
  (w_2 * asset2) + 
  (w_3 * asset3) +
  (w_4 * asset4) + 
  (w_5 * asset5)

names(portfolio_returns_byhand) <- "returns"

portfolio_returns_xts_rebalanced_monthly <- 
  Return.portfolio(asset_returns_xts, weights = w, rebalance_on = "months") %>%
  `colnames<-`("returns")

portfolio_returns_xts_rebalanced_yearly <- 
  Return.portfolio(asset_returns_xts, weights = w, rebalance_on = "years") %>%
  `colnames<-`("returns")

head(portfolio_returns_byhand)
head(portfolio_returns_xts_rebalanced_monthly)
head(portfolio_returns_xts_rebalanced_yearly)

# tidyquant way
portfolio_returns_tq_rebalanced_monthly <- 
  asset_returns_long %>%
  tq_portfolio(assets_col  = asset, 
               returns_col = returns,
               weights     = w,
               col_rename  = "returns",
               rebalance_on = "months")

portfolio_returns_tq_rebalanced_yearly <- 
  asset_returns_long %>%
  tq_portfolio(assets_col  = asset, 
               returns_col = returns,
               weights     = w,
               col_rename  = "returns",
               rebalance_on = "years")

head(portfolio_returns_tq_rebalanced_monthly)
head(portfolio_returns_tq_rebalanced_yearly)

```

# portfolio 2

```{r, echo = T}
library(timetk)
library(tidyverse)
library(tidyquant)
library(highcharter)

symbols <- c("SPY","IJS","EFA","EEM","AGG")

prices <- 
  getSymbols(symbols, src = 'google', from = "2005-01-01", 
             auto.assign = TRUE, warnings = FALSE) %>% 
  map(~Cl(get(.))) %>% 
  reduce(merge) %>%
  `colnames<-`(symbols)

prices_monthly <- to.monthly(prices, indexAt = "first", OHLC = FALSE)

portfolioComponentReturns <- na.omit(Return.calculate(prices_monthly, method = "log"))

w = c(0.25, 0.20, 0.20, 0.25, 0.10)

covariance_matrix <- cov(portfolioComponentReturns)

# Square root of transpose of the weights cross prod covariance matrix returns 
# cross prod weights gives portfolio standard deviation.
sd_portfolio <- sqrt(t(w) %*% covariance_matrix %*% w)

# Marginal contribution of each asset. 
marginal_contribution <- w %*% covariance_matrix / sd_portfolio[1, 1]

# Component contributions to risk are the weighted marginal contributions
component_contribution <- marginal_contribution * w 

# This should equal total portfolio vol, or the object `sd_portfolio`
components_summed <- rowSums(component_contribution)

# To get the percentage contribution, divide component contribution by total sd.
component_percentages <- component_contribution / sd_portfolio[1, 1]

percentage_tibble_by_hand <- 
  tibble(symbols, w, as.vector(component_percentages)) %>% 
  rename(asset = symbols, 'portfolio weight' = w, 'risk contribution' = `as.vector(component_percentages)`)

percentage_tibble_by_hand

component_sd_pre_built <- StdDev(portfolioComponentReturns, weights = w, 
                                 portfolio_method = "component")
component_sd_pre_built

# Port to a tibble.  
percentages_tibble_pre_built <- component_sd_pre_built$pct_contrib_StdDev %>%
  tk_tbl(preserve_row_names = FALSE) %>%
  mutate(asset = symbols) %>%
  rename('risk contribution' = data) %>% 
  select(asset, everything(), -index)

percentages_tibble_pre_built

percentage_tibble_by_hand

component_percent_plot <- 
  ggplot(percentage_tibble_by_hand, aes(asset, `risk contribution`)) +
  geom_col(fill = 'blue', colour = 'red') + 
  scale_y_continuous(labels = scales::percent) + 
  ggtitle("Percent Contribution to Volatility", 
          subtitle = "") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5)) +
  xlab("Asset") +
  ylab("Percent Contribution to Risk")

component_percent_plot

# gather
percentage_tibble_by_hand_gather <-
  percentage_tibble_by_hand %>% 
  gather(type, percent, -asset)

# built ggplot object
plot_compare_weight_contribution <- 
  ggplot(percentage_tibble_by_hand_gather, aes(x = asset, y = percent, fill = type)) +
  geom_col(position = 'dodge') + 
  scale_y_continuous(labels = scales::percent) + 
  ggtitle("Percent Contribution to Volatility", 
          subtitle = "") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5))

plot_compare_weight_contribution

EEM_sd <- StdDev(portfolioComponentReturns$EEM)

EEM_sd_overtime <- 
  round(rollapply(portfolioComponentReturns$EEM, 20, function(x) StdDev(x)), 4) * 100

highchart(type = "stock") %>%
  hc_title(text = "EEM Volatility") %>%
  hc_add_series(EEM_sd_overtime, name = "EEM Vol") %>%
  hc_yAxis(labels = list(format = "{value}%"), opposite = FALSE) %>%
  hc_navigator(enabled = FALSE) %>% 
  hc_scrollbar(enabled = FALSE)
```

# Commodity

```{r, echo = T}
```
# Assingment
1. Bank management
- Interface for adding new account/new transactions.
- We also need to generate management report:
    - Risk department: Total balance, total receivable, high-/low-risk client. Very active customer.
    - Interest rate payable.
    - ...

2. Delta Hedging
Show case how delta hedging works as a trading strategy.

- Show how one trading works
- Backtest for available history.

Assumption:

- You hold 10000 ATM option and start to do delta hedging immediately till 2nd last day.
- You can get your favorite stocks here. >=Three
https://marketchameleon.com/Overview/{Stock Code}/DailyHistory/
- IV30 is provided. Scale up for IV60 and IV90 with 252 trading days.
- As underlying is equity, dividend yield is applicable.
- US risk-free rate: https://www.quandl.com/data/USTREASURY/YIELD-Treasury-Yield-Curve-Rates

Strategy indicators:

- Daily PnL
- Final PnL
- Max Drawdown
- Sharpe ratio
- ...
- Graphics