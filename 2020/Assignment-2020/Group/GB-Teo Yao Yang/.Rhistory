for(c in daily_ret$XLK_cumret)
{
if(c>localmax)
{
localmax<-c
localmin<-100
}
if(c<localmin)
{
localmin<-c
}
if(((localmin-localmax)/localmax)<maxdd)
{
maxddxlk<-((localmin-localmax)/localmax)
}
}
localmax<--100
maxddxlp<-1000
for(c in daily_ret$XLP_cumret)
{
if(c>localmax)
{
localmax<-c
localmin<-100
}
if(c<localmin)
{
localmin<-c
}
if(((localmin-localmax)/localmax)<maxdd)
{
maxddxlp<-((localmin-localmax)/localmax)
}
}
localmax<--100
maxddxlu<-1000
for(c in daily_ret$XLU_cumret)
{
if(c>localmax)
{
localmax<-c
localmin<-100
}
if(c<localmin)
{
localmin<-c
}
if(((localmin-localmax)/localmax)<maxdd)
{
maxddxlu<-((localmin-localmax)/localmax)
}
}
localmax<--100
maxddxlv<-1000
for(c in daily_ret$XLV_cumret)
{
if(c>localmax)
{
localmax<-c
localmin<-100
}
if(c<localmin)
{
localmin<-c
}
if(((localmin-localmax)/localmax)<maxdd)
{
maxddxlv<-((localmin-localmax)/localmax)
}
}
localmax<--100
maxddxly<-1000
for(c in daily_ret$XLY_cumret)
{
if(c>localmax)
{
localmax<-c
localmin<-100
}
if(c<localmin)
{
localmin<-c
}
if(((localmin-localmax)/localmax)<maxdd)
{
maxddxly<-((localmin-localmax)/localmax)
}
}
all_tickers <- c('XLB','XLE','XLF','XLI','XLK','XLP','XLU','XLV','XLY','SPY')
mdd <- c()
mdd["XLB"]<-maxddxlb
mdd["XLE"]<-maxddxle
mdd["XLF"]<-maxddxlf
mdd["XLI"]<-maxddxli
mdd["XLK"]<-maxddxlk
mdd["XLP"]<-maxddxlp
mdd["XLU"]<-maxddxlu
mdd["XLV"]<-maxddxlv
mdd["XLY"]<-maxddxly
mdd
rank(-mdd)
# Calculate the Max DD
localmax<--100
i<-1
maxdd<-1000
for(c in daily_ret$EW_M_cumret)
{
if(c>localmax)
{
localmax<-c
localmin<-100
}
if(c<localmin)
{
localmin<-c
}
if(((localmin-localmax)/localmax)<maxdd)
{
maxdd<-((localmin-localmax)/localmax)
}
}
maximum_drawdown <- paste(round(maxdd*100,2),"%",sep="")
maximum_drawdown
# Calculate the Max DD
localmax<--100
i<-1
maxdd<-1000
for(c in daily_ret$EW_Y_cumret)
{
if(c>localmax)
{
localmax<-c
localmin<-100
}
if(c<localmin)
{
localmin<-c
}
if(((localmin-localmax)/localmax)<maxdd)
{
maxdd<-((localmin-localmax)/localmax)
}
}
maximum_drawdown <- paste(round(maxdd*100,2),"%",sep="")
maximum_drawdown
# Rank all ETFs by its contribution to PnL over the entire period.
# Rank all ETFs by its risk (max. draw down %) over the entire period
pnl <- c()
denominator<-((len_invest)*(tail(daily_ret$EW_cumret,1)/head(daily_ret$EW_cumret,1))-1)
pnl["XLB"]<-(tail(daily_ret$XLB_cumret,1)/head(daily_ret$XLB_cumret,1))/denominator
pnl["XLE"]<-(tail(daily_ret$XLE_cumret,1)/head(daily_ret$XLE_cumret,1))/denominator
pnl["XLF"]<-(tail(daily_ret$XLF_cumret,1)/head(daily_ret$XLF_cumret,1))/denominator
pnl["XLI"]<-(tail(daily_ret$XLI_cumret,1)/head(daily_ret$XLI_cumret,1))/denominator
pnl["XLK"]<-(tail(daily_ret$XLK_cumret,1)/head(daily_ret$XLK_cumret,1))/denominator
pnl["XLP"]<-(tail(daily_ret$XLP_cumret,1)/head(daily_ret$XLP_cumret,1))/denominator
pnl["XLU"]<-(tail(daily_ret$XLU_cumret,1)/head(daily_ret$XLU_cumret,1))/denominator
pnl["XLV"]<-(tail(daily_ret$XLV_cumret,1)/head(daily_ret$XLV_cumret,1))/denominator
pnl["XLY"]<-(tail(daily_ret$XLY_cumret,1)/head(daily_ret$XLY_cumret,1))/denominator
pnl
rank(-pnl)
daily_price <- tibble(Date = dd[[1]]$timestamp)
for (ii in 1:len_tickers) {
if (all_tickers[ii] == 'SPY') { next }
daily_price[all_tickers[ii]] <- dd[[ii]]$adjusted_close
}
w <- rep(1, len_invest) / len_invest
daily_ret['SW'] <- as.matrix(daily_ret[,2:(2+len_invest-1)]) %*% w
daily_ret['SW_cumret'] <- cumprod(daily_ret['SW'] + 1)
# Assume monthly re-balance
for (r in rebal_days_month) {
mm <- numeric(len_invest)
# Generate momentum
# print(mm)
for (ii in 1:len_invest) {
tt <- invest_tickers[ii]
# Use 1 if look-back period is not enough.
r_prev_d <- if_else(r > 1, r - 1, 1)
r_prev_m <- if_else(r > 21, r - 21, 1)
r_prev_y <- if_else(r > 252, r - 252, 1)
x <- (daily_price[r_prev_m,tt] - daily_price[r_prev_y,tt] ) / daily_price[r_prev_y,tt] - ( daily_price[r_prev_d,tt] - daily_price[r_prev_m,tt] ) / daily_price[r_prev_m,tt]
mm[ii] <- as.numeric(x)
}
# TODO: rank and allocation.
# print(mm)
# run one cycle first, then remove break
rank <- rank(mm)
compound=daily_ret[r-1,'SW_cumret']
for(i in 1:9)
{
if(i==rank[6]||i==rank[7]||i==rank[8]||i==rank[9])
{
w[i]<-compound/4
}
else
{
w[i]<-0
}
}
w <- as.vector(unlist(w))
daily_ret[r:nrow(daily_ret),'SW'] <-as.matrix(daily_ret[r:nrow(daily_ret),2:(2+len_invest-1)]) %*% w
list <-cumprod(daily_ret['SW'] + 1)
list <- list[r:nrow(list),]
daily_ret[r:nrow(daily_ret),'SW_cumret'] <- list
}
daily_ret %>% {plot(.$Date,.$SW,type='l')}
w <- rep(1, len_invest) / len_invest
daily_ret['SW_LandS'] <- as.matrix(daily_ret[,2:(2+len_invest-1)]) %*% w
daily_ret['SW_LandS_cumret'] <- cumprod(daily_ret['SW_LandS'] + 1)
# Assume monthly re-balance
for (r in rebal_days_month) {
mm <- numeric(len_invest)
# Generate momentum
# print(mm)
for (ii in 1:len_invest) {
tt <- invest_tickers[ii]
# Use 1 if look-back period is not enough.
r_prev_d <- if_else(r > 1, r - 1, 1)
r_prev_m <- if_else(r > 21, r - 21, 1)
r_prev_y <- if_else(r > 252, r - 252, 1)
x <- (daily_price[r_prev_m,tt] - daily_price[r_prev_y,tt] ) / daily_price[r_prev_y,tt] - ( daily_price[r_prev_d,tt] - daily_price[r_prev_m,tt] ) / daily_price[r_prev_m,tt]
mm[ii] <- as.numeric(x)
}
# TODO: rank and allocation.
# print(mm)
# run one cycle first, then remove break
rank <- rank(mm)
compound=daily_ret[r-1,'SW_LandS_cumret']
for(i in 1:9)
{
if(i==rank[8]||i==rank[9])
{
w[i]<-compound/4
}
if(i==rank[1]||i==rank[2])
{
w[i]<-(-compound/4)
}
else
{
w[i]<-0
}
}
w <- as.vector(unlist(w))
daily_ret[r:nrow(daily_ret),'SW_LandS'] <-as.matrix(daily_ret[r:nrow(daily_ret),2:(2+len_invest-1)]) %*% w
daily_ret$allreturn<-daily_ret$SW_LandS+rep(compound$SW_LandS_cumret[1]/2,5284)
list <-cumprod(daily_ret['allreturn'] + 1)
list <- list[r:nrow(list),]
daily_ret[r:nrow(daily_ret),'SW_LandS_cumret'] <- list
}
library(conflicted)
library(tidyverse)
library(lubridate)
library(alphavantager)
library(testit)
library(kableExtra)
conflict_prefer('last', 'dplyr')
conflict_prefer('lag', 'dplyr')
conflict_prefer('filter', 'dplyr')
options(dplyr.summarise.inform = FALSE)
# Change (FALSE) to (TRUE), when you need to download data.
# Usually you only need to run this once.
# Change file location
# 'XLC', 'XLRE' has shorter history, don't use them.
all_tickers <- c('XLB','XLE','XLF','XLI','XLK','XLP','XLU','XLV','XLY','SPY')
if (FALSE) {
av_api_key("5WZYQ22PJ7YB73U2")
for (tt in all_tickers) {
df_xlc <- av_get(tt, av_fun = "TIME_SERIES_DAILY_ADJUSTED", outputsize="full")
saveRDS(df_xlc, paste0("C:/TEMP/project",tt,".Rds"))
cat(paste(tt,min(df_xlc$timestamp),max(df_xlc$timestamp),"\n"))
}
}
# make sure all starts from the same time and same length.
wd <- 'E:/Dropbox/MFE/FE8828/2020/Assignment-2020/Group/GD-Chen Leran/Grp Assignment -Q3/Data/'
dd <- list()
for (tt in all_tickers) {
dd[[tt]] <- readRDS(paste0(wd,tt,".Rds"))
print(paste(tt, min(dd[[tt]]$timestamp), nrow(dd[[tt]])))
assert(min(dd[[tt]]$timestamp) == as.Date('1999-11-01'))
assign(paste0('df_',tolower(tt)), dd[[tt]], envir = .GlobalEnv)
}
plot(df_xlk$timestamp, df_xlk$adjusted_close,type='l')
points(df_xle$timestamp, df_xle$adjusted_close,col='red',type='l')
len_tickers <- length(all_tickers)
ii <- 1
daily_ret <- tail(tibble(Date = dd[[1]]$timestamp), -1)
for (ii in 1:len_tickers) {
daily_ret[all_tickers[ii]] <- tail(dd[[ii]]$adjusted_close / lag(dd[[ii]]$adjusted_close, 1)-1,-1)
}
for (ii in 1:len_tickers) {
daily_ret[paste0(all_tickers[ii],"_cumret")] <- cumprod(1 + daily_ret[all_tickers[ii]])
}
invest_tickers <- all_tickers[all_tickers != 'SPY']
len_invest <- length(invest_tickers)
w <- rep(1, len_invest) / len_invest
w
daily_ret['EW'] <- as.matrix(daily_ret[,2:(2+len_invest-1)]) %*% w
daily_ret %>% {plot(.$Date,.$EW,type='l')}
daily_ret['EW_cumret'] <- cumprod(daily_ret['EW'] + 1)
daily_ret %>% {plot(.$Date,.$SPY,type='l')}
daily_ret %>% {plot(.$Date,.$EW_cumret,type='l',col='red'); points(.$Date,.$SPY_cumret,type='l');}
# annualized return for EW
prod(daily_ret$EW + 1) ** (250 / length(daily_ret$EW))
# annualized return for SPY
prod(daily_ret$SPY + 1) ** (250 / length(daily_ret$SPY))
# simplified Sharp ratio
prod(daily_ret$EW + 1) ** (250 / length(daily_ret$EW)) / sd(daily_ret$EW) / sqrt(250)
prod(daily_ret$SPY + 1) ** (250 / length(daily_ret$SPY)) / sd(daily_ret$SPY) / sqrt(250)
# Calculate the Max DD
daily_ret['EW_cumret'] <- cumprod(daily_ret['EW'] + 1)
daily_ret['drawdown'] <- 1 - daily_ret['EW_cumret']/cummax(daily_ret['EW_cumret'])
max(daily_ret['drawdown'])
# maximum_drawdown <- '' in %
max(daily_ret['drawdown'])/max(daily_ret['EW_cumret'])*100
# Rank all ETFs by its contribution to PnL over the entire period.
price <- dd1 %>% select(starts_with("X") & ends_with("adjusted_close"))
library(conflicted)
library(tidyverse)
library(lubridate)
library(alphavantager)
library(testit)
library(kableExtra)
conflict_prefer('last', 'dplyr')
conflict_prefer('lag', 'dplyr')
conflict_prefer('filter', 'dplyr')
options(dplyr.summarise.inform = FALSE, pillar.sigfig = 6)
# Change (FALSE) to (TRUE), when you need to download data.
# Usually you only need to run this once.
# Change file location
# 'XLC', 'XLRE' has shorter history, don't use them.
all_tickers <- c('XLB','XLE','XLF','XLI','XLK','XLP','XLU','XLV','XLY','SPY')
# all_tickers <- c('XLY','SPY')
if (FALSE) {
av_api_key("")
for (tt in all_tickers) {
df_xlc <- av_get(tt, av_fun = "TIME_SERIES_DAILY_ADJUSTED", outputsize="full")
save(df_xlc, file = paste0("C:/Data/",tt,".Rda"))
cat(paste(tt,min(df_xlc$timestamp),max(df_xlc$timestamp),"\n"))
}
}
# make sure all starts from the same time and same length.
dd <- list()
wd <- 'E:/Dropbox/MFE/FE8828/2020/Assignment-2020/Group/GH-Xiang Guangpei/Q3/'
for (tt in all_tickers) {
dd[[tt]] <- readRDS(paste0(wd,tt,".Rds"))
print(paste(tt, min(dd[[tt]]$timestamp), nrow(dd[[tt]])))
assert(min(dd[[tt]]$timestamp) == as.Date('1999-11-01'))
assign(paste0('df_',tolower(tt)), dd[[tt]], envir = .GlobalEnv)
}
paste0(wd,tt,".Rds")
readRDS(paste0(wd,tt,".Rds"))
# make sure all starts from the same time and same length.
dd <- list()
wd <- 'E:/Dropbox/MFE/FE8828/2020/Assignment-2020/Group/GH-Xiang Guangpei/Q3/'
for (tt in all_tickers) {
dd[[tt]] <- readRDS(paste0(wd,tt,".Rda"))
print(paste(tt, min(dd[[tt]]$timestamp), nrow(dd[[tt]])))
assert(min(dd[[tt]]$timestamp) == as.Date('1999-11-01'))
assign(paste0('df_',tolower(tt)), dd[[tt]], envir = .GlobalEnv)
}
read(paste0(wd,tt,".Rda"))
load(paste0(wd,tt,".Rda"))
wd <- 'E:/Dropbox/MFE/FE8828/2020/Assignment-2020/Group/GH-Xiang Guangpei/Q3/'
load(paste0(wd,tt,".Rda"))
# make sure all starts from the same time and same length.
dd <- list()
wd <- 'E:/Dropbox/MFE/FE8828/2020/Assignment-2020/Group/GH-Xiang Guangpei/Q3/'
load(paste0(wd,tt,".Rda"))
# make sure all starts from the same time and same length.
dd <- list()
wd <- 'E:/Dropbox/MFE/FE8828/2020/Assignment-2020/Group/GH-Xiang Guangpei/Q3/'
for (tt in all_tickers) {
dd[[tt]] <- readRDS(paste0(wd,tt,".Rda"))
print(paste(tt, min(dd[[tt]]$timestamp), nrow(dd[[tt]])))
assert(min(dd[[tt]]$timestamp) == as.Date('1999-11-01'))
assign(paste0('df_',tolower(tt)), dd[[tt]], envir = .GlobalEnv)
}
library(conflicted)
library(tidyverse)
library(lubridate)
library(alphavantager)
library(testit)
library(kableExtra)
conflict_prefer('last', 'dplyr')
conflict_prefer('lag', 'dplyr')
conflict_prefer('filter', 'dplyr')
options(dplyr.summarise.inform = FALSE, pillar.sigfig = 6)
# Change (FALSE) to (TRUE), when you need to download data.
# Usually you only need to run this once.
# Change file location
# 'XLC', 'XLRE' has shorter history, don't use them.
all_tickers <- c('XLB','XLE','XLF','XLI','XLK','XLP','XLU','XLV','XLY','SPY')
# all_tickers <- c('XLY','SPY')
if (FALSE) {
av_api_key("")
for (tt in all_tickers) {
df_xlc <- av_get(tt, av_fun = "TIME_SERIES_DAILY_ADJUSTED", outputsize="full")
save(df_xlc, file = paste0("C:/Data/",tt,".Rda"))
cat(paste(tt,min(df_xlc$timestamp),max(df_xlc$timestamp),"\n"))
}
}
# make sure all starts from the same time and same length.
dd <- list()
wd <- 'E:/Dropbox/MFE/FE8828/2020/Assignment-2020/Group/GH-Xiang Guangpei/Q3/'
for (tt in all_tickers) {
dd[[tt]] <- readRDS(paste0(wd,tt,".Rda"))
print(paste(tt, min(dd[[tt]]$timestamp), nrow(dd[[tt]])))
assert(min(dd[[tt]]$timestamp) == as.Date('1999-11-01'))
assign(paste0('df_',tolower(tt)), dd[[tt]], envir = .GlobalEnv)
}
load(paste0(wd,tt,".Rda"))
# make sure all starts from the same time and same length.
dd <- list()
wd <- 'E:/Dropbox/MFE/FE8828/2020/Assignment-2020/Group/GD-Chen Leran/Grp Assignment -Q3/Data/'
for (tt in all_tickers) {
dd[[tt]] <- readRDS(paste0(wd,tt,".Rds"))
print(paste(tt, min(dd[[tt]]$timestamp), nrow(dd[[tt]])))
assert(min(dd[[tt]]$timestamp) == as.Date('1999-11-01'))
assign(paste0('df_',tolower(tt)), dd[[tt]], envir = .GlobalEnv)
}
len_tickers <- length(all_tickers)
library(conflicted)
library(tidyverse)
library(lubridate)
library(alphavantager)
library(testit)
library(kableExtra)
conflict_prefer('last', 'dplyr')
conflict_prefer('lag', 'dplyr')
conflict_prefer('filter', 'dplyr')
options(dplyr.summarise.inform = FALSE, pillar.sigfig = 6)
# Change (FALSE) to (TRUE), when you need to download data.
# Usually you only need to run this once.
# Change file location
# 'XLC', 'XLRE' has shorter history, don't use them.
all_tickers <- c('XLB','XLE','XLF','XLI','XLK','XLP','XLU','XLV','XLY','SPY')
# all_tickers <- c('XLY','SPY')
if (FALSE) {
av_api_key("")
for (tt in all_tickers) {
df_xlc <- av_get(tt, av_fun = "TIME_SERIES_DAILY_ADJUSTED", outputsize="full")
save(df_xlc, file = paste0("C:/Data/",tt,".Rda"))
cat(paste(tt,min(df_xlc$timestamp),max(df_xlc$timestamp),"\n"))
}
}
# make sure all starts from the same time and same length.
dd <- list()
wd <- 'E:/Dropbox/MFE/FE8828/2020/Assignment-2020/Group/GD-Chen Leran/Grp Assignment -Q3/Data/'
for (tt in all_tickers) {
dd[[tt]] <- readRDS(paste0(wd,tt,".Rds"))
print(paste(tt, min(dd[[tt]]$timestamp), nrow(dd[[tt]])))
assert(min(dd[[tt]]$timestamp) == as.Date('1999-11-01'))
assign(paste0('df_',tolower(tt)), dd[[tt]], envir = .GlobalEnv)
}
len_tickers <- length(all_tickers)
plot(df_xlk$timestamp, df_xlk$adjusted_close,type='l')
points(df_xle$timestamp, df_xle$adjusted_close,col='red',type='l')
len_tickers <- length(all_tickers)
ii <- 1
daily_ret <- tail(tibble(Date = dd[[1]]$timestamp), -1)
for (ii in 1:len_tickers) {
daily_ret[all_tickers[ii]] <- tail(dd[[ii]]$adjusted_close / lag(dd[[ii]]$adjusted_close, 1)-1,-1)
}
for (ii in 1:len_tickers) {
daily_ret[paste0(all_tickers[ii],"_cumret")] <- cumprod(1 + daily_ret[all_tickers[ii]])
}
invest_tickers <- all_tickers[all_tickers != 'SPY']
len_invest <- length(invest_tickers)
w <- rep(1, len_invest) / len_invest
w
daily_ret['EW'] <- as.matrix(daily_ret[,2:(2+len_invest-1)]) %*% w
daily_ret %>% {plot(.$Date,.$EW,type='l')}
daily_ret['EW_cumret'] <- cumprod(daily_ret['EW'] + 1)
daily_ret %>% {plot(.$Date,.$SPY,type='l')}
daily_ret %>% {plot(.$Date,.$EW_cumret,type='l',col='red'); points(.$Date,.$SPY_cumret,type='l');}
# annualized return for EW
prod(daily_ret$EW + 1) ** (250 / length(daily_ret$EW))
# annualized return for SPY
prod(daily_ret$SPY + 1) ** (250 / length(daily_ret$SPY))
# simplified Sharp ratio
prod(daily_ret$EW + 1) ** (250 / length(daily_ret$EW)) / sd(daily_ret$EW) / sqrt(250)
prod(daily_ret$SPY + 1) ** (250 / length(daily_ret$SPY)) / sd(daily_ret$SPY) / sqrt(250)
# Calculate the Max DD
# maximum_drawdown <- '' in %
maximum_drawdown <- function(table, column)
{
max_value <- table[1,column]
max_date <- "1999-11-01"
maximum_drawdown <- 0
col <- table[,column]
is_tracking <- FALSE
for (row in 2:nrow(daily_ret)) {
if (!is_tracking & col[row,] < max_value) {
is_tracking <- TRUE
} else if (col[row,] >= max_value) {
if (is_tracking) {
# Find the minimum value during the period
lowest <- min(filter(table, Date > max_date, Date < table$Date[row])[,column])
# Calculate drawdown during the period
drawdown <- (max_value - lowest) / max_value * 100
# print(paste(max_date, daily_ret$Date[row], max_value, daily_ret$EW_cumret[row], lowest, drawdown))
if (drawdown > maximum_drawdown) maximum_drawdown <- drawdown
is_tracking <- FALSE
}
max_value <- col[row,]
max_date <- table$Date[row]
}
}
maximum_drawdown
}
maximum_drawdown(daily_ret, "EW_cumret")
unlink('E:/Dropbox/MFE/FE8828/2020/Assignment-2020/Group/GH-Xiang Guangpei/Q3/port_invest_cache', recursive = TRUE)
